{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPsi4AHiRuHHF0jW10afPRy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emery1189/nlp_emotion_classifier/blob/main/emotion_from_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Emotion from Text"
      ],
      "metadata": {
        "id": "AE8-C8Opg7Gv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using a [Kaggle dataset](https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp), we will train a neural network to classify a piece of text into one of six emotions: anger, fear, joy, love, sadness, and surprise.\n",
        "\n",
        "we will:\n",
        "1. get the data into colab and import our tools\n",
        "2. use SKLearn's `MultinomialNB` to generate a baseline\n",
        "3. restructure the data to fit tensorflow's `text_dataset_from_directory()` utility.\n",
        "4. vectorize and embed our text\n",
        "5. build model(s) and fit\n",
        "6. create a `dectect_emotion()` function to predict emotion contained in a user generated sentence"
      ],
      "metadata": {
        "id": "PupzcC-ShK5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## getting data"
      ],
      "metadata": {
        "id": "OF1YryfEh2k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "lUFIzMXOh4VO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "C6KcISpfiQ_j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download praveengovi/emotions-dataset-for-nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPeRIKdWiWcy",
        "outputId": "35dff17a-ee3b-4e08-ab17-b9b99296005c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading emotions-dataset-for-nlp.zip to /content\n",
            "\r  0% 0.00/721k [00:00<?, ?B/s]\n",
            "\r100% 721k/721k [00:00<00:00, 132MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/emotions-dataset-for-nlp.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzwLkzqmicLD",
        "outputId": "c8b03789-dfc0-459d-d7db-9fdf92a8ebeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/emotions-dataset-for-nlp.zip\n",
            "  inflating: test.txt                \n",
            "  inflating: train.txt               \n",
            "  inflating: val.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "vnEq4mSTihw3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting sentences and labels"
      ],
      "metadata": {
        "id": "WX2f_xjSjto2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = []\n",
        "train_labels = []\n",
        "\n",
        "with open(\"/content/train.txt\") as train_file:\n",
        "  for line in train_file:\n",
        "    line = line.split(\";\")\n",
        "    train_sentences.append(line[0])\n",
        "    train_labels.append(line[1].rstrip())\n",
        "\n",
        "\n",
        "len(train_sentences), len(train_labels), train_sentences[1834], train_labels[1834]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbb5D5DJjw7k",
        "outputId": "16d1933e-7106-4af5-83ac-19b3e3e33c66"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16000, 16000, 'i instantly feel rejected', 'sadness')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_sentences = []\n",
        "valid_labels = []\n",
        "\n",
        "with open(\"/content/val.txt\") as valid_file:\n",
        "  for line in valid_file:\n",
        "    line = line.split(\";\")\n",
        "    valid_sentences.append(line[0])\n",
        "    valid_labels.append(line[1].rstrip())\n",
        "\n",
        "\n",
        "len(valid_sentences), len(valid_labels), valid_sentences[134], valid_labels[134]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVJjvto6kUKk",
        "outputId": "542fc056-2b1d-4fb2-99cc-3baf4b1bf6a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,\n",
              " 2000,\n",
              " 'i was feeling frightened to the core what if my friends laughed at me what if sir was too harsh what if',\n",
              " 'fear')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = []\n",
        "test_labels = []\n",
        "\n",
        "with open(\"/content/test.txt\") as test_file:\n",
        "  for line in test_file:\n",
        "    line = line.split(\";\")\n",
        "    test_sentences.append(line[0])\n",
        "    test_labels.append(line[1].rstrip())\n",
        "\n",
        "\n",
        "len(test_sentences), len(test_labels), test_sentences[184], test_labels[184]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srzuS_r7kkXB",
        "outputId": "bb23b254-24bf-4f8e-f8b0-415409bf9a43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,\n",
              " 2000,\n",
              " 'i feel terrified because my landlord has not changed our locks yet',\n",
              " 'fear')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## getting a baseline score with SKLearn's `MultinomialNB`"
      ],
      "metadata": {
        "id": "R8M7EU0Fh8ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create tokenization and modeling pipeline\n",
        "baseline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),  # convert words to numbers using tfidf\n",
        "    (\"clf\", MultinomialNB())  # model the text\n",
        "])\n",
        "\n",
        "# fit the pipeline to the training data\n",
        "baseline.fit(train_sentences, train_labels)\n",
        "\n",
        "baseline_score = baseline.score(test_sentences, test_labels)\n",
        "print(f\"baseline model accuracy: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1r5P17NiDJU",
        "outputId": "f944f485-f97f-4a63-f6e3-5b5e9d231485"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baseline model accuracy: 64.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## restructuring data"
      ],
      "metadata": {
        "id": "xMgKe0a8k6xA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "per tensorflow's `text_dataset_from_directory()`, we want our data in the following structure:\n",
        "\n",
        "main_directory/ <br>\n",
        "...class_a/<br>\n",
        "......a_text_1.txt<br>\n",
        "......a_text_2.txt<br>\n",
        "...class_b/<br>\n",
        "......b_text_1.txt<br>\n",
        "......b_text_2.txt<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "og72e-4zlJlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first, we'll need a train, test, and valid folders."
      ],
      "metadata": {
        "id": "lNFK_2mlloVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in [\"train\", \"test\", \"valid\"]:\n",
        "  os.mkdir(f\"{dataset}/\")"
      ],
      "metadata": {
        "id": "9hp2SXcClxV_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now each of the datasets will need a folder for each class (emotion)."
      ],
      "metadata": {
        "id": "hPja9c1Yl8GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for emotion in [\"anger\", \"fear\", \"joy\", \"love\", \"sadness\", \"surprise\"]:\n",
        "  os.mkdir(f\"/content/test/{emotion}/\")\n",
        "  os.mkdir(f\"/content/train/{emotion}/\")\n",
        "  os.mkdir(f\"/content/valid/{emotion}/\")"
      ],
      "metadata": {
        "id": "QhfnUfJ2mGAo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we need each example of an emotion to be its own .txt file in the associated folder."
      ],
      "metadata": {
        "id": "5Kjr4lospZOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for emotion in [\"anger\", \"fear\", \"joy\", \"love\", \"sadness\", \"surprise\"]:\n",
        "  p = 1\n",
        "  for i in range(len(train_sentences)):\n",
        "    if train_labels[i] == emotion:\n",
        "      with open(f\"/content/train/{emotion}/{emotion}_text_{p}.txt\", \"w\") as f:\n",
        "        f.write(train_sentences[i])\n",
        "        p += 1"
      ],
      "metadata": {
        "id": "y0PytFJIn8mf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for emotion in [\"anger\", \"fear\", \"joy\", \"love\", \"sadness\", \"surprise\"]:\n",
        "  p = 1\n",
        "  for i in range(len(test_sentences)):\n",
        "    if test_labels[i] == emotion:\n",
        "      with open(f\"/content/test/{emotion}/{emotion}_text_{p}.txt\", \"w\") as f:\n",
        "        f.write(test_sentences[i])\n",
        "        p += 1"
      ],
      "metadata": {
        "id": "htim0YUMo_u4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for emotion in [\"anger\", \"fear\", \"joy\", \"love\", \"sadness\", \"surprise\"]:\n",
        "  p = 1\n",
        "  for i in range(len(valid_sentences)):\n",
        "    if valid_labels[i] == emotion:\n",
        "      with open(f\"/content/valid/{emotion}/{emotion}_text_{p}.txt\", \"w\") as f:\n",
        "        f.write(valid_sentences[i])\n",
        "        p += 1"
      ],
      "metadata": {
        "id": "4YSORH4KpPY5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's see how many of each class we have:"
      ],
      "metadata": {
        "id": "I8ihDB3gz7Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_array = np.array(train_labels)\n",
        "\n",
        "uniques, count = np.unique(train_labels_array, return_counts=True)\n",
        "\n",
        "print(np.asarray((uniques, count)).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1CFMjfnpVv0",
        "outputId": "59627440-a139-4eba-ee09-6f18691a3081"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['anger' '2159']\n",
            " ['fear' '1937']\n",
            " ['joy' '5362']\n",
            " ['love' '1304']\n",
            " ['sadness' '4666']\n",
            " ['surprise' '572']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_labels_array = np.array(valid_labels)\n",
        "\n",
        "uniques, count = np.unique(valid_labels_array, return_counts=True)\n",
        "\n",
        "print(np.asarray((uniques, count)).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1CkYP9jp3J3",
        "outputId": "f29823d5-a59f-4f69-bf2d-e9a8c8a22f93"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['anger' '275']\n",
            " ['fear' '212']\n",
            " ['joy' '704']\n",
            " ['love' '178']\n",
            " ['sadness' '550']\n",
            " ['surprise' '81']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels_array = np.array(test_labels)\n",
        "\n",
        "uniques, count = np.unique(test_labels_array, return_counts=True)\n",
        "\n",
        "print(np.asarray((uniques, count)).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHuMKCHNqCSc",
        "outputId": "2fae46b3-9ef7-4aeb-a83a-2f8703774717"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['anger' '275']\n",
            " ['fear' '224']\n",
            " ['joy' '695']\n",
            " ['love' '159']\n",
            " ['sadness' '581']\n",
            " ['surprise' '66']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "perhaps not an ideal balance of classes, but we work with what we have."
      ],
      "metadata": {
        "id": "Id-8HUmc0DiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating `tf.Datasets`"
      ],
      "metadata": {
        "id": "J58eIM7C0VRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "seed = 42\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    '/content/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0,\n",
        "    seed=seed)\n",
        "\n",
        "class_names = raw_train_ds.class_names\n",
        "\n",
        "raw_valid_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    '/content/valid',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0,\n",
        "    seed=seed)\n",
        "\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    '/content/test',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0,\n",
        "    seed=seed)\n",
        "\n",
        "\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_ds = raw_valid_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = raw_test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4nRF9KSqGxE",
        "outputId": "c543d558-4790-486e-95d6-fb03b9ab6512"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16000 files belonging to 6 classes.\n",
            "Found 2000 files belonging to 6 classes.\n",
            "Found 2000 files belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(class_names)):\n",
        "  print(f\"label {i} corresponds to\", raw_train_ds.class_names[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFMNYNTarnaF",
        "outputId": "29b52591-6e58-405d-fc5c-eefdc17c3748"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label 0 corresponds to anger\n",
            "label 1 corresponds to fear\n",
            "label 2 corresponds to joy\n",
            "label 3 corresponds to love\n",
            "label 4 corresponds to sadness\n",
            "label 5 corresponds to surprise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## vectorize and embed text"
      ],
      "metadata": {
        "id": "dr_vZBtPsUe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the average number of tokens (words) in the training sentences\n",
        "\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxKXPBvhsc5Q",
        "outputId": "c4b14d62-a998-418e-ca2e-11603b0eb162"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=10000,\n",
        "                                                    output_mode=\"int\",\n",
        "                                                    output_sequence_length=19)"
      ],
      "metadata": {
        "id": "s2-J8xpzssx8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a text-only dataset (without labels) and call adapt\n",
        "\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "text_vectorizer.adapt(train_text)"
      ],
      "metadata": {
        "id": "9dwU_wz6tlYj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(input_dim=10000,\n",
        "                                            output_dim=64,\n",
        "                                            input_length=19)"
      ],
      "metadata": {
        "id": "InhBVzDAuHud"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[777]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9Qo1LlUplC91",
        "outputId": "8330f0a3-deee-4f10-d20d-24c13abf627a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i sometimes feel resentful that this has come into our lives at this time'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer(train_sentences[777])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2oW8zBslIUb",
        "outputId": "e60fdc82-e1b0-40e8-deab-186175f9db17"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(19,), dtype=int64, numpy=\n",
              "array([  2, 186,   3, 523,   8,  23,  99, 182, 106, 133, 684,  33,  23,\n",
              "        52,   0,   0,   0,   0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer(text_vectorizer(train_sentences[777]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0yvVky8lLFA",
        "outputId": "095f848b-7bb1-4a84-a7eb-e29cd534b941"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(19, 64), dtype=float32, numpy=\n",
              "array([[ 0.04218544,  0.02298843,  0.01594229, ..., -0.00779108,\n",
              "        -0.03963272, -0.01821632],\n",
              "       [ 0.02916528,  0.04562428, -0.04782431, ..., -0.00677817,\n",
              "        -0.02804784,  0.00100296],\n",
              "       [-0.03272986, -0.01396491,  0.00617515, ..., -0.01699731,\n",
              "         0.01951266,  0.02484052],\n",
              "       ...,\n",
              "       [-0.0076418 ,  0.01530791, -0.02656021, ...,  0.00044016,\n",
              "         0.04240118, -0.01912725],\n",
              "       [-0.0076418 ,  0.01530791, -0.02656021, ...,  0.00044016,\n",
              "         0.04240118, -0.01912725],\n",
              "       [-0.0076418 ,  0.01530791, -0.02656021, ...,  0.00044016,\n",
              "         0.04240118, -0.01912725]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## models"
      ],
      "metadata": {
        "id": "2jC7pE9v06A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=7,\n",
        "                                                  mode=\"auto\",\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "reduce_LOR = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                  patience=5,\n",
        "                                                  verbose=1)"
      ],
      "metadata": {
        "id": "cl1qEdIxjS1T"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dense model with `Flatten()` layer"
      ],
      "metadata": {
        "id": "F4N4UPr72dc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build (Sequential)\n",
        "model = tf.keras.Sequential([\n",
        "    text_vectorizer,\n",
        "    embedding_layer,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# compile\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# fit\n",
        "model.fit(train_ds,\n",
        "          epochs=50,\n",
        "          validation_data=valid_ds,\n",
        "          callbacks=[early_stopping, reduce_LOR])\n",
        "\n",
        "# evaluate\n",
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucZhkOJl2fS9",
        "outputId": "834501a6-9762-4cd1-80a5-90bea7a1edd6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 25s 40ms/step - loss: 1.4774 - accuracy: 0.4350 - val_loss: 1.2005 - val_accuracy: 0.5990 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.7752 - accuracy: 0.7701 - val_loss: 0.6778 - val_accuracy: 0.7890 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.3600 - accuracy: 0.9066 - val_loss: 0.5486 - val_accuracy: 0.8195 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2003 - accuracy: 0.9517 - val_loss: 0.5306 - val_accuracy: 0.8165 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1201 - accuracy: 0.9746 - val_loss: 0.5431 - val_accuracy: 0.8135 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0750 - accuracy: 0.9865 - val_loss: 0.5637 - val_accuracy: 0.8150 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0496 - accuracy: 0.9918 - val_loss: 0.5850 - val_accuracy: 0.8140 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "496/500 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9940\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.9939 - val_loss: 0.6056 - val_accuracy: 0.8120 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0240 - accuracy: 0.9966 - val_loss: 0.6057 - val_accuracy: 0.8140 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0226 - accuracy: 0.9966 - val_loss: 0.6076 - val_accuracy: 0.8140 - lr: 1.0000e-04\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.8195\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5691350102424622, 0.8195000290870667]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "82% on our test data. not bad!"
      ],
      "metadata": {
        "id": "CY7WjeUFA5ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dense model with `GlobalAveragePooling1D` layer"
      ],
      "metadata": {
        "id": "6VLXEoYS2OwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build\n",
        "model = tf.keras.Sequential([\n",
        "    text_vectorizer,\n",
        "    embedding_layer,\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(6, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# compile\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# fit\n",
        "model.fit(train_ds,\n",
        "          epochs=50,\n",
        "          validation_data=valid_ds,\n",
        "          callbacks=[early_stopping, reduce_LOR])\n",
        "\n",
        "# evaluate\n",
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwJEQw8WAQRm",
        "outputId": "715421c0-efd4-4953-943a-16df0d6de5d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 16s 29ms/step - loss: 1.4446 - accuracy: 0.5412 - val_loss: 1.2896 - val_accuracy: 0.5780 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.0450 - accuracy: 0.6896 - val_loss: 0.9680 - val_accuracy: 0.7185 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.7077 - accuracy: 0.8270 - val_loss: 0.7361 - val_accuracy: 0.7965 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.4922 - accuracy: 0.8825 - val_loss: 0.6066 - val_accuracy: 0.8285 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3660 - accuracy: 0.9114 - val_loss: 0.5413 - val_accuracy: 0.8300 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2913 - accuracy: 0.9253 - val_loss: 0.5121 - val_accuracy: 0.8275 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.2428 - accuracy: 0.9362 - val_loss: 0.5017 - val_accuracy: 0.8265 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.2066 - accuracy: 0.9437 - val_loss: 0.5022 - val_accuracy: 0.8260 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1795 - accuracy: 0.9517 - val_loss: 0.5092 - val_accuracy: 0.8260 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "492/500 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9587\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1566 - accuracy: 0.9588 - val_loss: 0.5207 - val_accuracy: 0.8255 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.1340 - accuracy: 0.9666 - val_loss: 0.5213 - val_accuracy: 0.8255 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1314 - accuracy: 0.9682 - val_loss: 0.5227 - val_accuracy: 0.8250 - lr: 1.0000e-04\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 0.5599 - accuracy: 0.8275\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5599210262298584, 0.8274999856948853]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "83% on our test data. moving in the right direction!"
      ],
      "metadata": {
        "id": "Nb_Cq1ynnrsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM model"
      ],
      "metadata": {
        "id": "FITCkSXEwTPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build (Functional)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding_layer(x)\n",
        "x = tf.keras.layers.LSTM(units=64, return_sequences=True)(x)\n",
        "x = tf.keras.layers.LSTM(64)(x)\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = tf.keras.layers.Dense(6, activation=\"softmax\")(x)\n",
        "\n",
        "lstm_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# compile\n",
        "lstm_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "# fit\n",
        "lstm_model.fit(train_ds,\n",
        "               epochs=50,\n",
        "               validation_data=valid_ds,\n",
        "               callbacks=[early_stopping, reduce_LOR])\n",
        "\n",
        "# evaluate\n",
        "lstm_model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "P0xFUy45zC3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5f579f-5a2c-4625-fd30-af1be18914b9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 23s 34ms/step - loss: 0.3610 - accuracy: 0.8832 - val_loss: 0.6255 - val_accuracy: 0.8030 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.1922 - accuracy: 0.9374 - val_loss: 0.6502 - val_accuracy: 0.8050 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.1396 - accuracy: 0.9553 - val_loss: 0.6925 - val_accuracy: 0.8085 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.1054 - accuracy: 0.9659 - val_loss: 0.7769 - val_accuracy: 0.8030 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0799 - accuracy: 0.9746 - val_loss: 0.8543 - val_accuracy: 0.8080 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0658 - accuracy: 0.9790 - val_loss: 0.8866 - val_accuracy: 0.8055 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0570 - accuracy: 0.9819 - val_loss: 0.9629 - val_accuracy: 0.8050 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9849\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0449 - accuracy: 0.9849 - val_loss: 1.0913 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 1.0409 - val_accuracy: 0.8160 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 1.0945 - val_accuracy: 0.8145 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 1.1407 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 1.1876 - val_accuracy: 0.8130 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 1.2348 - val_accuracy: 0.8115 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "493/500 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9937\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 1.2853 - val_accuracy: 0.8110 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 1.2847 - val_accuracy: 0.8150 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 1.2863 - val_accuracy: 0.8145 - lr: 1.0000e-05\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.1736 - accuracy: 0.7970\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1735920906066895, 0.796999990940094]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "80%"
      ],
      "metadata": {
        "id": "RjTyB7K1Fhmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU model"
      ],
      "metadata": {
        "id": "yZG26acbAASG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding_layer(x)\n",
        "x = tf.keras.layers.GRU(64, return_sequences=True)(x) # if stacking recurrent layers, use return_sequences=True\n",
        "x = tf.keras.layers.GRU(64)(x)\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = tf.keras.layers.Dense(6, activation=\"softmax\")(x)\n",
        "model_GRU = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "# compile\n",
        "model_GRU.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "# fit\n",
        "model_GRU.fit(train_ds,\n",
        "              epochs=50,\n",
        "              validation_data=valid_ds,\n",
        "              callbacks=[early_stopping, reduce_LOR])\n",
        "\n",
        "# evaluate\n",
        "model_GRU.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMaiDaeBDUmR",
        "outputId": "e0ac5c26-4774-458f-dad5-25b8c4a42016"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 21s 34ms/step - loss: 0.3234 - accuracy: 0.8899 - val_loss: 0.7096 - val_accuracy: 0.8025 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0853 - accuracy: 0.9724 - val_loss: 0.8440 - val_accuracy: 0.8095 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0569 - accuracy: 0.9824 - val_loss: 0.9402 - val_accuracy: 0.8150 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.9969 - val_accuracy: 0.8030 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0372 - accuracy: 0.9877 - val_loss: 1.1444 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0356 - accuracy: 0.9876 - val_loss: 1.1247 - val_accuracy: 0.8140 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 1.1610 - val_accuracy: 0.8235 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 1.3155 - val_accuracy: 0.8175 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 1.1366 - val_accuracy: 0.8255 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0227 - accuracy: 0.9917 - val_loss: 1.1952 - val_accuracy: 0.8185 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 1.3247 - val_accuracy: 0.8165 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 1.2561 - val_accuracy: 0.8200 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 1.3837 - val_accuracy: 0.8195 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9920\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0209 - accuracy: 0.9920 - val_loss: 1.2371 - val_accuracy: 0.8175 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0152 - accuracy: 0.9943 - val_loss: 1.2926 - val_accuracy: 0.8335 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0108 - accuracy: 0.9955 - val_loss: 1.3061 - val_accuracy: 0.8335 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 1.3233 - val_accuracy: 0.8340 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0087 - accuracy: 0.9959 - val_loss: 1.3439 - val_accuracy: 0.8335 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0082 - accuracy: 0.9961 - val_loss: 1.3657 - val_accuracy: 0.8325 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0078 - accuracy: 0.9961 - val_loss: 1.3874 - val_accuracy: 0.8335 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0075 - accuracy: 0.9961 - val_loss: 1.4098 - val_accuracy: 0.8330 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9961\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0073 - accuracy: 0.9961 - val_loss: 1.4312 - val_accuracy: 0.8340 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 1.4314 - val_accuracy: 0.8350 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0063 - accuracy: 0.9969 - val_loss: 1.4314 - val_accuracy: 0.8350 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 1.4318 - val_accuracy: 0.8350 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0061 - accuracy: 0.9971 - val_loss: 1.4327 - val_accuracy: 0.8355 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 1.4342 - val_accuracy: 0.8360 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 1.4364 - val_accuracy: 0.8360 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0059 - accuracy: 0.9972 - val_loss: 1.4389 - val_accuracy: 0.8355 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0059 - accuracy: 0.9972 - val_loss: 1.4417 - val_accuracy: 0.8355 - lr: 1.0000e-05\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 1.4446 - val_accuracy: 0.8355 - lr: 1.0000e-05\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9973\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 1.4479 - val_accuracy: 0.8355 - lr: 1.0000e-05\n",
            "Epoch 33/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 1.4481 - val_accuracy: 0.8355 - lr: 1.0000e-06\n",
            "Epoch 34/50\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 1.4483 - val_accuracy: 0.8355 - lr: 1.0000e-06\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.6014 - accuracy: 0.8170\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6014018058776855, 0.8169999718666077]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "82%"
      ],
      "metadata": {
        "id": "dg1xV3AkFkyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU with `Dropout()` layer"
      ],
      "metadata": {
        "id": "TE6JbLfrI9e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding_layer(x)\n",
        "x = tf.keras.layers.GRU(64, return_sequences=True)(x)\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.GRU(64)(x)\n",
        "x = tf.keras.layers.Dense(64)(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "outputs = tf.keras.layers.Dense(6, activation=\"softmax\")(x)\n",
        "\n",
        "GRU_model_2 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# compile\n",
        "GRU_model_2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                            optimizer=tf.keras.optimizers.Adam(),\n",
        "                            metrics=[\"accuracy\"])\n",
        "\n",
        "# fit\n",
        "GRU_model_2.fit(train_ds,\n",
        "                epochs=50,\n",
        "                validation_data=valid_ds,\n",
        "                callbacks=[early_stopping, reduce_LOR])\n",
        "\n",
        "# evaluate\n",
        "GRU_model_2.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fswgk2diI4uN",
        "outputId": "1e5979f7-fcc6-49d4-94ed-413e2c371540"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 23s 35ms/step - loss: 0.2934 - accuracy: 0.8953 - val_loss: 0.7569 - val_accuracy: 0.8185 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0459 - accuracy: 0.9855 - val_loss: 1.0767 - val_accuracy: 0.8125 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 1.1461 - val_accuracy: 0.8170 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 1.1809 - val_accuracy: 0.8160 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 1.4029 - val_accuracy: 0.8155 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 5s 11ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 1.1698 - val_accuracy: 0.8265 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 1.2870 - val_accuracy: 0.8180 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 1.3322 - val_accuracy: 0.8110 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 1.2167 - val_accuracy: 0.8200 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 1.2540 - val_accuracy: 0.8165 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "497/500 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9930\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 1.3137 - val_accuracy: 0.8190 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 1.2550 - val_accuracy: 0.8305 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 1.2626 - val_accuracy: 0.8305 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0089 - accuracy: 0.9962 - val_loss: 1.2792 - val_accuracy: 0.8320 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0089 - accuracy: 0.9957 - val_loss: 1.2930 - val_accuracy: 0.8325 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0083 - accuracy: 0.9962 - val_loss: 1.3116 - val_accuracy: 0.8310 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0077 - accuracy: 0.9966 - val_loss: 1.3354 - val_accuracy: 0.8320 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0077 - accuracy: 0.9962 - val_loss: 1.3517 - val_accuracy: 0.8315 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.0069 - accuracy: 0.9966 - val_loss: 1.3735 - val_accuracy: 0.8315 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9967\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0070 - accuracy: 0.9967 - val_loss: 1.3872 - val_accuracy: 0.8320 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 1.3887 - val_accuracy: 0.8305 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 1.3902 - val_accuracy: 0.8310 - lr: 1.0000e-05\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1.3718 - accuracy: 0.8110\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3717806339263916, 0.8109999895095825]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "81%"
      ],
      "metadata": {
        "id": "-4IvWTpYHVze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv1D model"
      ],
      "metadata": {
        "id": "AT04gZP1GGp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding_layer(x)\n",
        "x = tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.GlobalMaxPool1D()(x)\n",
        "outputs = tf.keras.layers.Dense(6, activation=\"softmax\")(x)\n",
        "model_conv1d = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "# compile\n",
        "model_conv1d.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "# fit\n",
        "model_conv1d.fit(train_ds,\n",
        "                 epochs=50,\n",
        "                 validation_data=valid_ds,\n",
        "                 callbacks=[early_stopping, reduce_LOR])\n",
        "\n",
        "# evaluate\n",
        "model_conv1d.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThF4kizPGSfk",
        "outputId": "6ecfa567-2124-49bc-b6c8-a1e55756d53d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 16s 30ms/step - loss: 0.2532 - accuracy: 0.9249 - val_loss: 0.4898 - val_accuracy: 0.8330 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.1005 - accuracy: 0.9736 - val_loss: 0.5892 - val_accuracy: 0.8340 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0571 - accuracy: 0.9856 - val_loss: 0.6796 - val_accuracy: 0.8320 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.7663 - val_accuracy: 0.8310 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0244 - accuracy: 0.9940 - val_loss: 0.8354 - val_accuracy: 0.8290 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.8992 - val_accuracy: 0.8260 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9954\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.9557 - val_accuracy: 0.8275 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.9732 - val_accuracy: 0.8335 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.9810 - val_accuracy: 0.8340 - lr: 1.0000e-04\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.8170\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6569477915763855, 0.8169999718666077]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "82%"
      ],
      "metadata": {
        "id": "R4tvclxVH_SM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model with Universal Sentence Encoder"
      ],
      "metadata": {
        "id": "36RS_hWJB8gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load in USE layer from TF Hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # the input to the USE is variable lenght, so we assign our input_shape as nothing\n",
        "                                        dtype=tf.string,\n",
        "                                        name=\"USE\")\n",
        "\n",
        "# build model\n",
        "model_USE = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    tf.keras.layers.Dense(6, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# compile\n",
        "model_USE.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "# fit\n",
        "model_USE.fit(train_ds,\n",
        "              epochs=50,\n",
        "              validation_data=valid_ds,\n",
        "              callbacks=[early_stopping, reduce_LOR])\n",
        "\n",
        "# evaluate\n",
        "model_USE.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpFf79TcB_7P",
        "outputId": "47d821cd-1fd3-4aa6-e510-d5c0be2d5b3c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 14s 20ms/step - loss: 1.4764 - accuracy: 0.4856 - val_loss: 1.3401 - val_accuracy: 0.5355 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 1.2575 - accuracy: 0.5614 - val_loss: 1.2044 - val_accuracy: 0.5835 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 9s 18ms/step - loss: 1.1531 - accuracy: 0.5986 - val_loss: 1.1261 - val_accuracy: 0.6060 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 1.0905 - accuracy: 0.6150 - val_loss: 1.0772 - val_accuracy: 0.6220 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 1.0495 - accuracy: 0.6249 - val_loss: 1.0448 - val_accuracy: 0.6265 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 1.0210 - accuracy: 0.6308 - val_loss: 1.0222 - val_accuracy: 0.6310 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 9s 18ms/step - loss: 1.0002 - accuracy: 0.6365 - val_loss: 1.0059 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 7s 15ms/step - loss: 0.9843 - accuracy: 0.6409 - val_loss: 0.9937 - val_accuracy: 0.6425 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.9718 - accuracy: 0.6443 - val_loss: 0.9844 - val_accuracy: 0.6445 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 9s 17ms/step - loss: 0.9617 - accuracy: 0.6469 - val_loss: 0.9771 - val_accuracy: 0.6455 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 7s 13ms/step - loss: 0.9534 - accuracy: 0.6504 - val_loss: 0.9713 - val_accuracy: 0.6440 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 6s 13ms/step - loss: 0.9464 - accuracy: 0.6522 - val_loss: 0.9667 - val_accuracy: 0.6445 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.9404 - accuracy: 0.6549 - val_loss: 0.9629 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 7s 15ms/step - loss: 0.9353 - accuracy: 0.6578 - val_loss: 0.9597 - val_accuracy: 0.6440 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "496/500 [============================>.] - ETA: 0s - loss: 0.9306 - accuracy: 0.6595\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "500/500 [==============================] - 6s 13ms/step - loss: 0.9308 - accuracy: 0.6589 - val_loss: 0.9571 - val_accuracy: 0.6440 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 6s 13ms/step - loss: 0.9260 - accuracy: 0.6603 - val_loss: 0.9571 - val_accuracy: 0.6440 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 9s 18ms/step - loss: 0.9255 - accuracy: 0.6613 - val_loss: 0.9571 - val_accuracy: 0.6430 - lr: 1.0000e-04\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.9945 - accuracy: 0.6325\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9944573044776917, 0.6324999928474426]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recreating our best model"
      ],
      "metadata": {
        "id": "c5IuS-AuJYFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    text_vectorizer,\n",
        "    embedding_layer,\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(6, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(train_ds,\n",
        "          epochs=50,\n",
        "          validation_data=valid_ds,\n",
        "          callbacks=[early_stopping, reduce_LOR])\n",
        "\n",
        "\n",
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0beR1OqhJa-L",
        "outputId": "a075e8bc-1f97-4330-f0eb-04fe5b8d0b3c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 15s 28ms/step - loss: 0.9907 - accuracy: 0.7481 - val_loss: 0.7685 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.4108 - accuracy: 0.9321 - val_loss: 0.5691 - val_accuracy: 0.8285 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2524 - accuracy: 0.9532 - val_loss: 0.5156 - val_accuracy: 0.8265 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1880 - accuracy: 0.9602 - val_loss: 0.5053 - val_accuracy: 0.8270 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1549 - accuracy: 0.9653 - val_loss: 0.5100 - val_accuracy: 0.8275 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1320 - accuracy: 0.9687 - val_loss: 0.5235 - val_accuracy: 0.8285 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "492/500 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9707\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.1163 - accuracy: 0.9708 - val_loss: 0.5401 - val_accuracy: 0.8280 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.1023 - accuracy: 0.9759 - val_loss: 0.5415 - val_accuracy: 0.8285 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1001 - accuracy: 0.9750 - val_loss: 0.5434 - val_accuracy: 0.8285 - lr: 1.0000e-04\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.8265\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5902280807495117, 0.8264999985694885]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### examining model preds"
      ],
      "metadata": {
        "id": "FftoBAWaDOBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_preds = model.predict(test_ds)\n",
        "\n",
        "\n",
        "# let's take a look at one of our preds\n",
        "\n",
        "model_preds[13]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al6yiexxMjhZ",
        "outputId": "d0de328e-90b9-4a56-e90f-e8e700e17887"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00814457, 0.00919383, 0.89692247, 0.01242341, 0.00296762,\n",
              "       0.0703481 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_preds[13].argmax(), class_names[model_preds[13].argmax()], test_labels[13], test_sentences[13]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csNE23J5Qtsz",
        "outputId": "3a34aeec-c96f-4ad2-df24-df4c953c29da"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " 'joy',\n",
              " 'joy',\n",
              " 'i just feel extremely comfortable with the group of people that i dont even need to hide myself')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_sample_sentence = \"I went to the store and got some really great stuff\""
      ],
      "metadata": {
        "id": "OeU7ByCsRc1x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_pred = model.predict([my_sample_sentence])\n",
        "\n",
        "print(f\"predicted emotion: {class_names[sample_pred.argmax()]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD1UvApfRmUH",
        "outputId": "934dc260-2ae0-4275-f4d2-61b3b80dcaa1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 105ms/step\n",
            "predicted emotion: joy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating a `detect_emotion()` function"
      ],
      "metadata": {
        "id": "EYl2NLLmU5xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_dict = {\"anger\" : \"\",\n",
        "                \"fear\" : \"\",\n",
        "                \"joy\" : \"\",\n",
        "                \"love\" : \"\",\n",
        "                \"sadness\" : \"\",\n",
        "                \"surprise\" : \"\"}"
      ],
      "metadata": {
        "id": "w6mY6KtUS1mk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def detect_emotion():\n",
        "  user_text = input(\"please enter a sentence: \")\n",
        "  prediction = model.predict([user_text])\n",
        "  clear_output()\n",
        "  emotion = class_names[prediction.argmax()]\n",
        "  print(f\"\\n{user_text}\\n\\nemotion dectected in your sentence: {emotion}.\\n          {emotion_dict[emotion]}\")"
      ],
      "metadata": {
        "id": "KnFMuwHIRwcs"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_emotion()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sUSgAL3TOGh",
        "outputId": "926d37c0-1a3e-4c22-ca23-72521874e3ae"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "the sun is shining bright in every direction\n",
            "\n",
            "emotion dectected in your sentence: joy.\n",
            "          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detect_emotion()"
      ],
      "metadata": {
        "id": "C_3jJyfj8CfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94380e3-51cf-4c40-f9a9-2984063d0fc5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "i find myself terrified of rainbows.\n",
            "\n",
            "emotion dectected in your sentence: fear.\n",
            "          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detect_emotion()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVNtpWk9Vb3z",
        "outputId": "8e05dad1-bd9b-462d-e6e4-b5753960b776"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "i am glad to be at the end of another project\n",
            "\n",
            "emotion dectected in your sentence: joy.\n",
            "          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LwKkM78ddGOe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}